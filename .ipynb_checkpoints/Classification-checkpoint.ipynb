{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GO_BTacqAhQu",
    "outputId": "9506a21f-5b5f-4ed8-ae77-cf8ed670dae0"
   },
   "outputs": [],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Loo5nAm3isr-"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchsummary\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import grpc\n",
    "from loss_pb2 import LossRequest, LossResponse\n",
    "from loss_pb2_grpc import TrainModelServicer, add_TrainModelServicer_to_server\n",
    "from image_pb2 import ImageLabelRequest, ImageLabelResponse\n",
    "from image_pb2_grpc import ImageLabelServiceServicer, add_ImageLabelServiceServicer_to_server\n",
    "from concurrent import futures\n",
    "import threading\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torchvision.transforms import ToPILImage\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTHqm65SAfIf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFn7xQOrglNo",
    "outputId": "d932c3cc-3825-48e6-926a-e5e3c31e8f26"
   },
   "outputs": [],
   "source": [
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter()\n",
    "])\n",
    "\n",
    "# Download the CIFAR-10 dataset\n",
    "train_full = datasets.CIFAR10(root=\"./data\", train=True, transform=TRANSFORMS, download=True)\n",
    "\n",
    "# Define the size of the subset (e.g., 10% of the original training set)\n",
    "subset_size = int(0.1 * len(train_full))\n",
    "\n",
    "# Create a random subset of the training set\n",
    "subset_indices = np.random.choice(len(train_full), size=subset_size, replace=False)\n",
    "train_subset = Subset(train_full, subset_indices)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "train_dl = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Get the list of classes in the dataset\n",
    "classes = train_full.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwcPOeHGguwv",
    "outputId": "208ec751-c295-4e49-d38b-088df7373dc9"
   },
   "outputs": [],
   "source": [
    "test = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                 train=False,\n",
    "                                 transform=TRANSFORMS,\n",
    "                                 download=True)\n",
    "\n",
    "test_dl = DataLoader(test,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False,\n",
    "                    num_workers=0)\n",
    "\n",
    "dataloaders ={'train': train_dl, 'valid': test_dl, 'test': test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "IeVuF-a0jvcM",
    "outputId": "d612e43c-b02a-4929-dc83-e1418e0b2fe9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_IMAGES = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, N_IMAGES, figsize=(17,7))\n",
    "\n",
    "for i in range(N_IMAGES):\n",
    "    im, lbl = train_full[i]\n",
    "\n",
    "    ax[i].imshow(im[0,:,:], 'gray', interpolation='bilinear')\n",
    "    ax[i].set_title(f'{classes[lbl]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLuHXfVE_H-i"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.layer1 = self.ConvModule(in_features=3, out_features=64)      #16,16\n",
    "        self.layer2 = self.ConvModule(in_features=64, out_features=128)    #8,8\n",
    "        self.layer3 = self.ConvModule(in_features=128, out_features=256)   #4,4\n",
    "        self.layer4 = self.ConvModule(in_features=256, out_features=512)   #2,2\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                        nn.Linear(2*2*512, 1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(1024, 512),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(512,10),\n",
    "                                        nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def ConvModule(self, in_features, out_features):\n",
    "        return nn.Sequential(nn.Conv2d(in_channels=in_features, out_channels=out_features, kernel_size=3, padding=1),\n",
    "                            nn.BatchNorm2d(out_features),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2,2)\n",
    "                            )\n",
    "\n",
    "model = CustomCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCD_VSPa_qi-",
    "outputId": "28201171-bdca-4335-e82a-ec5cc7a043dd"
   },
   "outputs": [],
   "source": [
    "torchsummary.summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUWITjGCAZYI"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 35\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e_UBeHTBiy0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "losses_per_iter = []\n",
    "\n",
    "iteration = 0\n",
    "#current_image_data = None\n",
    "\n",
    "\n",
    "gt_labels = []\n",
    "pred_labels = []\n",
    "image_data_list = []\n",
    "\n",
    "mutex = threading.Lock()\n",
    "\n",
    "\n",
    "loss_available = threading.Condition(mutex)\n",
    "\n",
    "class TrainModelService(TrainModelServicer):\n",
    "    def TrainModel(self, request, context):\n",
    "        # Simulate sending loss response for the iteration requested\n",
    "        global iteration\n",
    "        \n",
    "\n",
    "        \n",
    "            # Once a loss is available, increment the iteration and pop the first loss from the list\n",
    "        iteration += 1\n",
    "        cur_iteration = iteration\n",
    "        loss = losses_per_iter.pop(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        response = LossResponse(iteration=cur_iteration, loss=loss) \n",
    "        return response\n",
    "        \n",
    "class ImageLabelService(ImageLabelServiceServicer):\n",
    "    def GetImagePrediction(self, request, context):\n",
    "        # Simulate getting image data, ground truth label, and prediction label\n",
    "        # Replace these lines with your actual image processing and prediction logic\n",
    "        # Assuming inputs, labels, and preds are global variables holding the current iteration's data\n",
    "       \n",
    "        global gt, pred, current_image_data\n",
    "        global mutex\n",
    "        \n",
    "      \n",
    "        \n",
    "      \n",
    "        \n",
    "        # Get ground truth label and prediction label\n",
    "        #with mutex:\n",
    "        if gt_labels and pred_labels and image_data_list:\n",
    "            gt_label = gt_labels.pop(0)\n",
    "            pred_label = pred_labels.pop(0)\n",
    "            current_image_data = image_data_list.pop(0)\n",
    "            \n",
    "        #gt_label = gt\n",
    "        #pred_label = pred\n",
    "    \n",
    "    \n",
    "            \n",
    "            # Create and return the ImageLabelResponse\n",
    "        response = ImageLabelResponse(\n",
    "            iteration=request.iteration,\n",
    "            image_data=current_image_data,\n",
    "            ground_truth_label=gt_label,\n",
    "            prediction_label=pred_label\n",
    "        )\n",
    "        return response\n",
    "            \n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    test_acc_history = []\n",
    "    test_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "    ]\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "\n",
    "        #BELOW, original is ['train', 'test']\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # training mode\n",
    "            else:\n",
    "                model.eval()   # evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "              \n",
    "                #print(labels)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    #print('outputs:', outputs)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                #convert all images in batch to bytes\n",
    "                #print('preds', preds)\n",
    "                if phase == 'train':\n",
    "                    for i in range(len(inputs)):\n",
    "                        global gt, pred, current_image_data\n",
    "                        global mutex\n",
    "                        \n",
    "                        \n",
    "                        img_byte_arr = BytesIO()\n",
    "                        img = ToPILImage()(inputs[i])\n",
    "                        \n",
    "                        #resize image because it is small\n",
    "                        img = img.resize((img.width * 2, img.height * 2), Image.BILINEAR)\n",
    "                        img.save(img_byte_arr, format='JPEG')\n",
    "    \n",
    "                        #current_image_data = img_byte_arr.getvalue()\n",
    "                        \n",
    "                        #get ground truth label\n",
    "                        gt_label = class_names[labels[i].item()]\n",
    "                        pred_label = class_names[preds[i].item()]\n",
    "    \n",
    "                        #with mutex:\n",
    "                        #print('ground truth:', gt_label)\n",
    "                        #print('prediction:', pred_label)\n",
    "                            #gt = gt_label\n",
    "                            #pred = pred_label\n",
    "                        gt_labels.append(gt_label)\n",
    "                        pred_labels.append(pred_label)\n",
    "                        image_data_list.append(img_byte_arr.getvalue())\n",
    "                            \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total_samples += len(inputs)\n",
    "            \n",
    "                #only track training loss\n",
    "                if phase == 'train':\n",
    "                    losses_per_iter.append(loss.item())\n",
    "\n",
    "                # Print training loss per iteration\n",
    "                if phase == 'train':\n",
    "                    print(f'Epoch [{epoch+1}/{num_epochs}], Iteration [{batch_idx+1}/{len(dataloaders[phase])}], Loss: {loss.item():.4f}')\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'test':\n",
    "                test_acc_history.append(epoch_acc.cpu().numpy())\n",
    "                test_loss_history.append(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc.cpu().numpy())\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    history_dict = {'train_loss':train_loss_history, 'train_accuracy':train_acc_history,\n",
    "                    'test_loss':test_loss_history, 'test_accuracy':test_acc_history}\n",
    "    return model, history_dict\n",
    "def start_grpc_server():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    add_TrainModelServicer_to_server(TrainModelService(), server)\n",
    "    add_ImageLabelServiceServicer_to_server(ImageLabelService(), server)\n",
    "    \n",
    "    server.add_insecure_port('[::]:50051')\n",
    "    server.start()\n",
    "    print(\"gRPC Server started on port 50051.\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(300)  # One day in seconds\n",
    "    except KeyboardInterrupt:\n",
    "        server.stop(0)\n",
    "\n",
    "grpc_server_thread = threading.Thread(target=start_grpc_server)\n",
    "grpc_server_thread.start()\n",
    "trained_model, history_dict = train_model(model, dataloaders, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NpqbcWnB6Cb",
    "outputId": "3ab6e9b1-710e-4ebd-fbac-2f619621fba1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Call the train_model function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oaUC5xfEpzh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
